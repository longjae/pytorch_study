{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNEDiSkquJ+3cYFtIoiITK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/longjae/pytorch_study/blob/master/tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor\n",
        "- 텐서(tensor)는 배열(Array)나 행렬(matrix)과 매우 유사한 특수한 자료구조\n",
        "- PyTorch에서는 텐서를 사용하여 모델의 입력과 출력 그리고 모델의 매개변수들을 부호화(encode)함\n",
        "- 텐서는 GPU나 다른 하드웨어 가속기에서 실행할 수 있다는 점만 제외하며 NumPy의 ndarray와 유사함\n",
        "- 실제로 텐서와 NumPy 배열(Array)은 종종 동일한 내부 메모리를 공유할 수 있어 데이터를 복사할 필요가 없음\n",
        "- 텐서는 또한 자동 미분에 최적화되어 있음"
      ],
      "metadata": {
        "id": "oZ_uPy6xgUsJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pDmWrAwCgPtn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서(tensor) 초기화\n",
        "- 텐서는 여러가지 방법으로 초기화할 수 있음\n",
        "# 데이터로부터 직접(directly) 생성하기\n",
        "- 데이터로부터 직접 텐서를 생성할 수 있음\n",
        "- 데이터의 자료형(data type)은 자동으로 유추함"
      ],
      "metadata": {
        "id": "77Rb4O6ChGOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "xUGPStoLg8u4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy 배열로부터 생성하기\n",
        "- 텐서는 NumPy 배열로 생성할 수 있음"
      ],
      "metadata": {
        "id": "ufSxqVA4hiSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "9uCWBQiShgq-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다른 텐서로부터 생성하기\n",
        "- 명시적으로 재정의(override)하지 않는다면, 인자로 주어진 텐서의 속성(모양(shape), 자료형(datatype))을 유지함"
      ],
      "metadata": {
        "id": "YY7lfdtZhxRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data)\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92GJCcNShtyb",
        "outputId": "5412eccf-982b-4240-f97c-565baabd1d0f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.0526, 0.2916],\n",
            "        [0.7641, 0.9474]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 무작위(random) 또는 상수(constant) 값을 사용하기\n",
        "- shape은 텐서의 차원(dimension)을 나타내는 튜플(tuple)로, 출력 텐서의 차원을 결정함"
      ],
      "metadata": {
        "id": "7fvGlCoQiWCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2, 3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjXWghd_iOP4",
        "outputId": "81e9232b-e623-45c7-b381-9934ab4c2ec0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.5334, 0.2418, 0.6037],\n",
            "        [0.1197, 0.4772, 0.5735]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서의 속성(Attribute)\n",
        "- 텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타냄"
      ],
      "metadata": {
        "id": "Qeesgu1Ejz9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GliDbShEi32j",
        "outputId": "e8292cff-8f67-4bcb-f724-31de51da0a83"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서 연산(Operation)\n",
        "- 전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, 임의 샘플링(random sampling) 등, 100가지 이상의 텐서 연산들을 수행할 수 있음\n"
      ],
      "metadata": {
        "id": "-KzxdXE4kawn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU가 존재하면 텐서를 이동함\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to(\"cuda\")"
      ],
      "metadata": {
        "id": "h3wiWUPZkKkp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy식의 표준 인덱싱과 슬라이싱"
      ],
      "metadata": {
        "id": "TjX_eACJlgJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[..., -1]}\")\n",
        "tensor[:, 1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLuZkNrmk7rJ",
        "outputId": "d2b360de-b0d3-478f-b14e-0206693968d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 텐서 합치기\n",
        "- torch.cat을 사용하여 주어진 차원에 따라 일련의 텐서를 연결할 수 있음"
      ],
      "metadata": {
        "id": "glEkAoRblfr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkjnYvVek7Wk",
        "outputId": "12378c9e-5dfd-48ae-ea0a-0a9917d919d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 산술 연산(Arithmetic operations)"
      ],
      "metadata": {
        "id": "O4mONHedl4jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산함\n",
        "# y1, y2, y3은 모두 같은 값을 가짐\n",
        "# tensor.T는 텐서의 전치(transpose)를 반환\n",
        "\n",
        "y1 = tensor @ tensor.T # @ -> 행렬곱셈 연산자\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "# 요소별 곱(element-wise product)를 계산함\n",
        "# z1, z2, z3는 모두 같은 값을 가짐\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgQcNKpXl1gI",
        "outputId": "b4189809-e9e7-470e-fea7-4125059a4274"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 단일-요소(single-element) 텐서\n",
        "- 텐서의 모든 값을 하나로 집계(aggregate)하여 요소가 하나인 텐서인 경우, item()을 사용하여 python 숫자 값으로 변환할 수 있음"
      ],
      "metadata": {
        "id": "eZlQOGV1nPPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQSvSwMumkY8",
        "outputId": "d1573c59-c5a3-4a4c-c2ca-289944186f4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 바꿔치기(in-place) 연산\n",
        "- 연산 결과를 피연산자(operand)에 저장하는 연산을 바꿔치기 연산이라고 부르며, _ 접미사를 가짐\n",
        "  - 예를 들어: x.copy_(y)나 x.t_()는 x를 변경함\n",
        "- 바꿔치기 연산은 메모리를 일부 절약하지만, 기록(history)이 즉시 삭제되어 도함수(derivate) 계산에 문제가 발생할 수 있음\n",
        "  - 사용을 권장하지 않음"
      ],
      "metadata": {
        "id": "u6IRymuFnm0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApNfFUgSnhQv",
        "outputId": "f5453752-d7a5-4164-a4f3-38141ebecb41"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.mul_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3pQZ9mHn8sL",
        "outputId": "d8ab0ba6-3ce2-4342-b6f2-435ba212f29e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]]) \n",
            "\n",
            "tensor([[30., 25., 30., 30.],\n",
            "        [30., 25., 30., 30.],\n",
            "        [30., 25., 30., 30.],\n",
            "        [30., 25., 30., 30.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NumPy 변환(Bridge)\n",
        "- CPU 상의 텐서와 NumPy 배열은 메모리 공간을 공유하기 떄문에, 하나를 변경하면 다른 하나도 변경됨\n",
        "### 텐서를 NumPy 배열로 변환하기"
      ],
      "metadata": {
        "id": "fVqkm0Fuocig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XogdX0uroGjo",
        "outputId": "f7b4a74c-8c9a-4e4d-dddd-83e8ac877e31"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebmDuARsow46",
        "outputId": "33e6f4fd-1378-4dea-acd9-4272fce70525"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy 배열을 텐서로 변환하기"
      ],
      "metadata": {
        "id": "6c8BteKso4qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "metadata": {
        "id": "0SYdQ5y0o2We"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCzRiqsOo_NT",
        "outputId": "655b545d-9220-41ff-926b-15a643c8217b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ljf130TBpDzK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}